,texts,labels
0,we present high dispersion spectroscopic data of the compact planetary nebula vy 1 2 where high expansion velocities up to 100 km s are found in the ha n ii and o iii emission lines hst images reveal a bipolar structure vy 1 2 displays a bright ring like structure with a size of 2 4 2 and two faint bipolar lobes in the west east direction a faint pair of knots is also found located almost on opposite sides of the nebula at pa degrees furthermore deep low dispersion spectra are also presented and several emission lines are detected for the first time in this nebula such as the doublet cl iii a k iv a c ii 6461 a the doublet c iv 5801 5812 a by comparison with the solar abundances we find enhanced n depleted c and solar o the central star must have experienced the hot bottom burning cn cycle during the 2nd dredge up phase implying a progenitor star of higher than 3 solar masses the ver,0
1,sdfsfd ssdfs,0
2,sasdas asdas asdasdasd rsgsg adasda asdffd sdfsdfs,0
3,This is not a true arxiv abstract,0
4,"A sizable amount of goodness-of-fit tests involving functional data have appeared in the last decade. We provide a relatively compact revision of most of these contributions, within the independent and identically distributed framework, by reviewing goodness-of-fit tests for distribution and regression models with functional predictor and either scalar or functional response.",1
5,"Multiple imputation is increasingly used in dealing with missing data. While some conventional multiple imputation approaches are well studied and have shown empirical validity, they entail limitations in processing large datasets with complex data structures. Their imputation performances usually rely on expert knowledge of the inherent relations among variables. In addition, these standard approaches tend to be computationally inefficient for medium and large datasets. In this paper, we propose a scalable multiple imputation framework mixgb, which is based on XGBoost, bootstrapping and predictive mean matching. XGBoost, one of the fastest implementations of gradient boosted trees, is able to automatically retain interactions and non-linear relations in a dataset while achieving high computational efficiency. With the aid of bootstrapping and predictive mean matching, we show that our approach obtains less biased estimates and reflects appropriate imputation variability. The proposed framework is implemented in an R package misle. Supplementary materials for this article are available online.",1
6,Hello world,0
7,Some random text,0
8,"Learning with neural networks relies on the complexity of the representable functions, but more importantly, the particular assignment of typical parameters to functions of different complexity. Taking the number of activation regions as a complexity measure, recent works have shown that the practical complexity of deep ReLU networks is often far from the theoretical maximum. In this work we show that this phenomenon also occurs in networks with maxout (multi-argument) activation functions and when considering the decision boundaries in classification tasks. We also show that the parameter space has a multitude of full-dimensional regions with widely different complexity, and obtain nontrivial lower bounds on the expected complexity. Finally, we investigate different parameter initialization procedures and show that they can increase the speed of convergence in training. ",1
9,Awesome match ,0
10,"Wikipedia began as a complementary project for Nupedia, a free online English-language encyclopedia projec",0
11," We consider the problem of model selection for the general stochastic contextual bandits under the realizability assumption. We propose a successive refinement based algorithm called Adaptive Contextual Bandit ({\ttfamily ACB}), that works in phases and successively eliminates model classes that are too simple to fit the given instance. We prove that this algorithm is adaptive, i.e., the regret rate order-wise matches that of {\ttfamily FALCON}, the state-of-art contextual bandit algorithm of Levi et. al '20, that needs knowledge of the true model class. The price of not knowing the correct model class is only an additive term contributing to the second order term in the regret bound. This cost possess the intuitive property that it becomes smaller as the model class becomes easier to identify, and vice-versa. We then show that a much simpler explore-then-commit (ETC) style algorithm also obtains a regret rate of matching that of {\ttfamily FALCON}, despite not knowing the true model class. However, the cost of model selection is higher in ETC as opposed to in {\ttfamily ACB}, as expected. Furthermore, {\ttfamily ACB} applied to the linear bandit setting with unknown sparsity, order-wise recovers the model selection guarantees previously established by algorithms tailored to the linear setting. ",1
12,"Recent works have revealed that infinitely-wide feed-forward or recurrent neural networks of any architecture correspond to Gaussian processes referred to as NNGP. While these works have extended the class of neural networks converging to Gaussian processes significantly, however, there has been little focus on broadening the class of stochastic processes that such neural networks converge to. In this work, inspired by the scale mixture of Gaussian random variables, we propose the scale mixture of NNGP for which we introduce a prior distribution on the scale of the last-layer parameters. We show that simply introducing a scale prior on the last-layer parameters can turn infinitely-wide neural networks of any architecture into a richer class of stochastic processes. Especially, with certain scale priors, we obtain heavy-tailed stochastic processes, and we recover Student's t processes in the case of inverse gamma priors. We further analyze the distributions of the neural networks initialized with our prior setting and trained with gradient descents and obtain similar results as for NNGP. We present a practical posterior-inference algorithm for the scale mixture of NNGP and empirically demonstrate its usefulness on regression and classification tasks. ",1
13,"Greece has administered at least 9,717,834 doses of COVID vaccines so far. Assuming every person needs 2 doses, that’s enough to have vaccinated about 45.3% of the country’s population.",0
14,"Enjoying an idyllic location directly on the beach promenade in the Baltic Sea resort of Ahlbeck, on the island of Usedom, this 5-star hotel offers wonderful dining and spa facilities. ",0
15,"Detecting abrupt changes in temporal behavior patterns is of interest in many industrial and security applications. Abrupt changes are often local and observable primarily through a well-aligned sensing action (e.g., a camera with a narrow field-of-view). Due to resource constraints, continuous monitoring of all of the sensors is impractical. We propose the bandit quickest changepoint detection framework as a means of balancing sensing cost with detection delay. In this framework, sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low false alarm rates, establishing optimality of the proposed method. We then perform a number of experiments on synthetic and real datasets demonstrating the efficacy of our proposed method. ",1
16,"Mother Earth’s beauty never fails to surprise us. One might come across many bizarre things on this planet. These sometimes even leave the scientists puzzled. Places like the stone hedge, gigantic pyramids, multi-shaded lakes, crooked trees fascinate us profusely to date.",0
17,"A solution that is only reliable under favourable conditions is hardly a safe solution. Min Max Optimization is an approach that returns optima that are robust against worst case conditions. We propose algorithms that perform Min Max Optimization in a setting where the function that should be optimized is not known a priori and hence has to be learned by experiments. Therefore we extend the Bayesian Optimization setting, which is tailored to maximization problems, to Min Max Optimization problems. While related work extends the two acquisition functions Expected Improvement and Gaussian Process Upper Confidence Bound; we extend the two acquisition functions Entropy Search and Knowledge Gradient. These acquisition functions are able to gain knowledge about the optimum instead of just looking for points that are supposed to be optimal. In our evaluation we show that these acquisition functions allow for better solutions - converging faster to the optimum than the benchmark settings. ",1
18,Measuring current performance against the company-level OKRs (goals),0
19,"NASA was established in 1958, succeeding the National Advisory Committee for Aeronautics (NACA). The new agency was to have a distinctly civilian orientation, encouraging peaceful applications in space science. Since its establishment, most US space exploration efforts have been led by NASA, including the Apollo Moon landing missions, the Skylab space station, and later the Space Shuttle.",0
20,"In modern deep learning, there is a recent and growing literature on the interplay between large-width asymptotics for deep Gaussian neural networks (NNs), i.e. deep NNs with Gaussian-distributed weights, and classes of Gaussian stochastic processes (SPs). Such an interplay has proved to be critical in several contexts of practical interest, e.g. Bayesian inference under Gaussian SP priors, kernel regression for infinite-wide deep NNs trained via gradient descent, and information propagation within infinite-wide NNs. Motivated by empirical analysis, showing the potential of replacing Gaussian distributions with Stable distributions for the NN's weights, in this paper we investigate large-width asymptotics for (fully connected) feed-forward deep Stable NNs, i.e. deep NNs with Stable-distributed weights. First, we show that as the width goes to infinity jointly over the NN's layers, a suitable rescaled deep Stable NN converges weakly to a Stable SP whose distribution is characterized recursively through the NN's layers. Because of the non-triangular NN's structure, this is a non-standard asymptotic problem, to which we propose a novel and self-contained inductive approach, which may be of independent interest. Then, we establish sup-norm convergence rates of a deep Stable NN to a Stable SP, quantifying the critical difference between the settings of ``joint growth"" and ``sequential growth"" of the width over the NN's layers. Our work extends recent results on infinite-wide limits for deep Gaussian NNs to the more general deep Stable NNs, providing the first result on convergence rates for infinite-wide deep NNs. ",1
21,"We develop variational Laplace for Bayesian neural networks (BNNs) which exploits a local approximation of the curvature of the likelihood to estimate the ELBO without the need for stochastic sampling of the neural-network weights. The Variational Laplace objective is simple to evaluate, as it is (in essence) the log-likelihood, plus weight-decay, plus a squared-gradient regularizer. Variational Laplace gave better test performance and expected calibration errors than maximum a-posteriori inference and standard sampling-based variational inference, despite using the same variational approximate posterior. Finally, we emphasise care needed in benchmarking standard VI as there is a risk of stopping before the variance parameters have converged. We show that early-stopping can be avoided by increasing the learning rate for the variance parameters. ",1
22,"Portrait of Wally is a 1912 oil-on-canvas painting by the Austrian artist Egon Schiele, depicting the young model Walburga Neuzil. Although little is known of the subject, she might have been one of his mistresses, and died tragically at a very young age. The painting had been owned by Lea Bondi, a Jewish art dealer who was fleeing the German annexation of Austria and had to sell it in 1939. Restituted to the owners only in 2010, the work now forms part of the collection of the Leopold Museum in Vienna. ",0
23,"Max Verstappen beat Lewis Hamilton to pole position at the Dutch Grand Prix by just 0.038 seconds, sending his devoted home fans wild.",0
24,"Methods for building fair predictors often involve tradeoffs between fairness and accuracy and between different fairness criteria, but the nature of these tradeoffs varies. Recent work seeks to characterize these tradeoffs in specific problem settings, but these methods often do not accommodate users who wish to improve the fairness of an existing benchmark model without sacrificing accuracy, or vice versa. These results are also typically restricted to observable accuracy and fairness criteria. We develop a flexible framework for fair ensemble learning that allows users to efficiently explore the fairness-accuracy space or to improve the fairness or accuracy of a benchmark model. Our framework can simultaneously target multiple observable or counterfactual fairness criteria, and it enables users to combine a large number of previously trained and newly trained predictors. We provide theoretical guarantees that our estimators converge at fast rates. We apply our method on both simulated and real data, with respect to both observable and counterfactual accuracy and fairness criteria. We show that, surprisingly, multiple unfairness measures can sometimes be minimized simultaneously with little impact on accuracy, relative to unconstrained predictors or existing benchmark models. ",1
25,Novak Djokovic is one win away from a record-breaking 21st major title and the first calendar grand slam in men's singles since 1969.,0
26,A puppy born with upside-down paws received successful treatment and learned to walk,0
27,"We introduce WildWood (WW), a new ensemble algorithm for supervised learning of Random Forest (RF) type. While standard RF algorithms use bootstrap out-of-bag samples to compute out-of-bag scores, WW uses these samples to produce improved predictions given by an aggregation of the predictions of all possible subtrees of each fully grown tree in the forest. This is achieved by aggregation with exponential weights computed over out-of-bag samples, that are computed exactly and very efficiently thanks to an algorithm called context tree weighting. This improvement, combined with a histogram strategy to accelerate split finding, makes WW fast and competitive compared with other well-established ensemble methods, such as standard RF and extreme gradient boosting algorithms. ",1
28,"Despite all the promises to take action, the world is still on course to heat up to dangerous levels.That's the latest blunt assessment of the United Nations. ",0
29,"Isaac Asimov's Foundation novels are among the greatest sci-fi books ever written – but no one has dared to film them, until now. The result is a true TV event, writes Neil Armstrong.",0
30,"This paper defines fair principal component analysis (PCA) as minimizing the maximum mean discrepancy (MMD) between dimensionality-reduced conditional distributions of different protected classes. The incorporation of MMD naturally leads to an exact and tractable mathematical formulation of fairness with good statistical properties. We formulate the problem of fair PCA subject to MMD constraints as a non-convex optimization over the Stiefel manifold and solve it using the Riemannian Exact Penalty Method with Smoothing (REPMS; Liu and Boumal, 2019). Importantly, we provide local optimality guarantees and explicitly show the theoretical effect of each hyperparameter in practical settings, extending previous results. Experimental comparisons based on synthetic and UCI datasets show that our approach outperforms prior work in explained variance, fairness, and runtime. ",1
31,"But despite all the visual stimulus, it was the architecture that dominated the scene. Sana'a is filled with buildings unlike anywhere else in the world. At street level, where mud-brick walls are only broken up by large wooden doors, there was often not much to see. But when I looked up, I realised these slender buildings, some with just one or two rooms to a floor, soared high into the sky. ",0
32,"The best horrors seem to imitate the fragile, visceral quality of your worst nightmares, some of which were spawned in your youth; transcending reality and making us feel like no other genre does. And ‘the scary place’ plays into that fear brilliantly.",0
33,"Recurrent neural networks (RNNs) are wide-spread machine learning tools for modeling sequential and time series data. They are notoriously hard to train because their loss gradients backpropagated in time tend to saturate or diverge during training. This is known as the exploding and vanishing gradient problem. Previous solutions to this issue either built on rather complicated, purpose-engineered architectures with gated memory buffers, or - more recently - imposed constraints that ensure convergence to a fixed point or restrict (the eigenspectrum of) the recurrence matrix. Such constraints, however, convey severe limitations on the expressivity of the RNN. Essential intrinsic dynamics such as multistability or chaos are disabled. This is inherently at disaccord with the chaotic nature of many, if not most, time series encountered in nature and society. Here we offer a comprehensive theoretical treatment of this problem by relating the loss gradients during RNN training to the Lyapunov spectrum of RNN-generated orbits. We mathematically prove that RNNs producing stable equilibrium or cyclic behavior have bounded gradients, whereas the gradients of RNNs with chaotic dynamics always diverge. Based on these analyses and insights, we offer an effective yet simple training technique for chaotic data and guidance on how to choose relevant hyperparameters according to the Lyapunov spectrum. ",1
34,"Harry Maguire, to put it very politely, was ring rusty on his return from a calf strain. He ran the ball out of play with his first touch. He was robbed by Kelechi Iheanacho in the build-up to Youri Tielemans' strike to make it 1-1 and was part of a defence lacking any sort of composure. He looked well short of match fitness.",0
35,"The result is a list that stands as a true testament to the power, versatility and innovation of the medium over the last two decades, from smalltown saga Gilmore Girls and caustic meta-comedy Curb Your Enthusiasm, which both kicked off in the immediate shadow of the new millennium in October 2000, to the most recent entry, Barry Jenkins' transcendent adaptation of alt-history epic The Underground Railroad, which premiered in May 2021. ",0
36,"The last decade has seen the rise of Adversarial Machine Learning (AML). This discipline studies how to manipulate data to fool inference engines, and how to protect those systems against such manipulation attacks. Extensive work on attacks against regression and classification systems is available, while little attention has been paid to attacks against time series forecasting systems. In this paper, we propose a decision analysis based attacking strategy that could be utilized against Bayesian forecasting dynamic models. ",1
37,"Around this period, the Mayan civilisation suffered a major political collapse, marked by the abandonment of cities dotted around modern-day Central America - leaving ruins of towering pyramids and other stone buildings. No single theory for this collapse has been widely accepted, but it's believed a combination of internal warfare, drought and overpopulation may have been contributing factors.",0
38,"The G20 group - made up of 19 countries and the European Union - is estimated to account for 80% of the world's carbon dioxide emissions. Italy's Prime Minister Mario Draghi opened the two-day summit, telling world leaders that ""going it alone is simply not an option. We must do all we can to overcome our differences"".",0
39,"We present a mathematical framework and computational methods to optimally design a finite number of sequential experiments. We formulate this sequential optimal experimental design (sOED) problem as a finite-horizon partially observable Markov decision process (POMDP) in a Bayesian setting and with information-theoretic utilities. It is built to accommodate continuous random variables, general non-Gaussian posteriors, and expensive nonlinear forward models. sOED then seeks an optimal design policy that incorporates elements of both feedback and lookahead, generalizing the suboptimal batch and greedy designs. We solve for the sOED policy numerically via policy gradient (PG) methods from reinforcement learning, and derive and prove the PG expression for sOED. Adopting an actor-critic approach, we parameterize the policy and value functions using deep neural networks and improve them using gradient estimates produced from simulated episodes of designs and observations. The overall PG-sOED method is validated on a linear-Gaussian benchmark, and its advantages over batch and greedy designs are demonstrated through a contaminant source inversion problem in a convection-diffusion field. ",1
40,"With growing numbers of electric vehicles, combined with increased demand for electricity to replace fossil fuels in domestic and industrial uses, electricity networks will also need to become far more flexible with more ways to generate and store energy. It means that by 2045, our energy network could look radically different to the way it does today.",0
41,"Recruitment firm PageGroup cites annual salaries for data science work of between £60,000-150,000, while cautioning that the job title covers a huge range of disciplines and responsibilities. ",0
42," For Bayesian optimization (BO) on high-dimensional data with complex structure, neural network-based kernels for Gaussian processes (GPs) have been used to learn flexible surrogate functions by the high representation power of deep learning. However, existing methods train neural networks by maximizing the marginal likelihood, which do not directly improve the BO performance. In this paper, we propose a meta-learning method for BO with neural network-based kernels that minimizes the expected gap between the true optimum value and the best value found by BO. We model a policy, which takes the current evaluated data points as input and outputs the next data point to be evaluated, by a neural network, where neural network-based kernels, GPs, and mutual information-based acquisition functions are used as its layers. With our model, the neural network-based kernel is trained to be appropriate for the acquisition function by backpropagating the gap through the acquisition function and GP. Our model is trained by a reinforcement learning framework from multiple tasks. Since the neural network is shared across different tasks, we can gather knowledge on BO from multiple training tasks, and use the knowledge for unseen test tasks. In experiments using three text document datasets, we demonstrate that the proposed method achieves better BO performance than the existing methods. ",1
43,"Even with modern building techniques, there's an appetite among architects to make the most of local materials. Indigo cabin in The Netherlands by Woonpioniers is lined with locally-sourced wood inside and out – spruce and black-stained larch respectively. And Norway's Aure Boathouse by TYIN Tegnestue is clad in Norwegian pine.",0
44,"Dr Kluge said factors like the winter season, insufficient vaccine coverage and the regional dominance of the more transmissible Delta variant were behind the spread. He called for increased vaccine uptake and the implementation of basic public health measures and new medical treatments to help fight the rise. ",0
45,"The Wasserstein distance, rooted in optimal transport (OT) theory, is a popular discrepancy measure between probability distributions with various applications to statistics and machine learning. Despite their rich structure and demonstrated utility, Wasserstein distances are sensitive to outliers in the considered distributions, which hinders applicability in practice. Inspired by the Huber contamination model, we propose a new outlier-robust Wasserstein distance Wεp which allows for ε outlier mass to be removed from each contaminated distribution. Our formulation amounts to a highly regular optimization problem that lends itself better for analysis compared to previously considered frameworks. Leveraging this, we conduct a thorough theoretical study of Wεp, encompassing characterization of optimal perturbations, regularity, duality, and statistical estimation and robustness results. In particular, by decoupling the optimization variables, we arrive at a simple dual form for Wεp that can be implemented via an elementary modification to standard, duality-based OT solvers. We illustrate the benefits of our framework via applications to generative modeling with contaminated datasets. ",1
46,"Barcelona tackles roaming wild boar problem. Barcelona is one of a number of European communities which have large numbers of wild boar living nearby and they have become a common presence in the city itself. The singer Shakira, who lives in Barcelona, recently complained that a boar had attacked her in a park, and encounters between locals and the animals have been on the increase. ",0
47,"As we reach the end of the Black Friday, it is great to see that the trend we have been seeing throughout the day has continued, and retailers will be happy that today's trading figures have surpassed those secured in 2019.",0
48,"Neural networks in the lazy training regime converge to kernel machines. Can neural networks in the rich feature learning regime learn a kernel machine with a data-dependent kernel? We demonstrate that this can indeed happen due to a phenomenon we term silent alignment, which requires that the tangent kernel of a network evolves in eigenstructure while small and before the loss appreciably decreases, and grows only in overall scale afterwards. We show that such an effect takes place in homogenous neural networks with small initialization and whitened data. We provide an analytical treatment of this effect in the linear network case. In general, we find that the kernel develops a low-rank contribution in the early phase of training, and then evolves in overall scale, yielding a function equivalent to a kernel regression solution with the final network's tangent kernel. The early spectral learning of the kernel depends on both depth and on relative learning rates in each layer. We also demonstrate that non-whitened data can weaken the silent alignment effect. ",1
49,"Since that time, a large body of research has revealed that honey is chock-full of plant chemicals that influence honey bee health. Components in honey can help bees live longer, boost their tolerance of harsh conditions such as intense cold and heighten their ability to fight off infections and heal wounds. The findings hint at ways to help bees, which have been hit hard in recent years by parasites, pesticide exposure and habitat loss.",0
50,"To get to space, you need two things: to be far away from populated areas; and to be as close to the equator as possible to take advantage of the Earth's rotational speed, which is fastest at that contour of the planet. In the case of the US space programme, this meant the east coast of Florida, where the Kennedy Space Center was built. The Soviet Union, meanwhile, went to the Kazakh Soviet Socialist Republic in search of a remote locale within its borders that could accommodate long-range missile testing and rocket launches.",0
51,"Changepoint analysis deals with unsupervised detection and/or estimation of time-points in time-series data, when the distribution generating the data changes. In this article, we consider \emph{offline} changepoint detection in the context of large scale textual data. We build a specialised temporal topic model with provisions for changepoints in the distribution of topic proportions. As full likelihood based inference in this model is computationally intractable, we develop a computationally tractable approximate inference procedure. More specifically, we use sample splitting to estimate topic polytopes first and then apply a likelihood ratio statistic together with a modified version of the wild binary segmentation algorithm of Fryzlewicz et al. (2014). Our methodology facilitates automated detection of structural changes in large corpora without the need of manual processing by domain experts. As changepoints under our model correspond to changes in topic structure, the estimated changepoints are often highly interpretable as marking the surge or decline in popularity of a fashionable topic. We apply our procedure on two large datasets: (i) a corpus of English literature from the period 1800-1922 (Underwoodet al., 2015); (ii) abstracts from the High Energy Physics arXiv repository (Clementet al., 2019). We obtain some historically well-known changepoints and discover some new ones. ",1
52,"Sullivan believes that while one or two short stints on a resume can be explained away, employers “could interpret a series of brief stints as a candidate who may avoid challenges or isn’t reliable”. Companies also don’t want to invest time and money recruiting and onboarding staff only to see them leave soon afterwards – which means they’ll lean towards recruits who have solid stints with previous firms under their belts.",0
53,"But as Canada's largest city has now reached an 85% vaccination rate among those 12 and older, its vibrant dining scene and walkable waterfront is bouncing back, welcoming back locals and fully vaccinated travellers as of August.",0
54,"The use of deep neural networks as function approximators has led to striking progress for reinforcement learning algorithms and applications. Yet the knowledge we have on decision boundary geometry and the loss landscape of neural policies is still quite limited. In this paper we propose a framework to investigate the decision boundary and loss landscape similarities across states and across MDPs. We conduct experiments in various games from Arcade Learning Environment, and discover that high sensitivity directions for neural policies are correlated across MDPs. We argue that these high sensitivity directions support the hypothesis that non-robust features are shared across training environments of reinforcement learning agents. We believe our results reveal fundamental properties of the environments used in deep reinforcement learning training, and represent a tangible step towards building robust and reliable deep reinforcement learning agents. ",1
55,"There is plenty to salivate over in the latest crop of bijou-and-basic cabins. These designers have turned simplicity into an art form, making an austere and minimalist lifestyle seem aspirational. Is that because of the effort and love that has clearly gone into creating more with less?",0
56,"New Zealand Prime Minister Jacinda Ardern says the tsunami wreaked ""significant damage"", washing boats ashore and battering beachside shops. Information from Tonga is scarce but no deaths have been reported so far. ",0
57,"Conjoint analysis is a popular experimental design used to measure multidimensional preferences. Researchers examine how varying a factor of interest, while controlling for other relevant factors, influences decision-making. Currently, there exist two methodological approaches to analyzing data from a conjoint experiment. The first focuses on estimating the average marginal effects of each factor while averaging over the other factors. Although this allows for straightforward design-based estimation, the results critically depend on the distribution of other factors and how interaction effects are aggregated. An alternative model-based approach can compute various quantities of interest, but requires researchers to correctly specify the model, a challenging task for conjoint analysis with many factors and possible interactions. In addition, a commonly used logistic regression has poor statistical properties even with a moderate number of factors when incorporating interactions. We propose a new hypothesis testing approach based on the conditional randomization test to answer the most fundamental question of conjoint analysis: Does a factor of interest matter in any way given the other factors? Our methodology is solely based on the randomization of factors, and hence is free from assumptions. Yet, it allows researchers to use any test statistic, including those based on complex machine learning algorithms. As a result, we are able to combine the strengths of the existing design-based and model-based approaches. We illustrate the proposed methodology through conjoint analysis of immigration preferences and political candidate evaluation. We also extend the proposed approach to test for regularity assumptions commonly used in conjoint analysis.",1
58,"A 75-year-old Frenchman who was trying to row across the Atlantic Ocean has been found dead at sea, his support team said.Adventurer Jean-Jacques Savin had previously made the crossing in a large barrel in 2019. ""Unfortunately, this time the ocean was stronger than our friend, who loved sailing and the sea so much,"" a statement on his Facebook page said. Savin had triggered two distress beacons on Thursday night.",0
59,"There are many hidden forces at play that shape a new mother's identity, biology and physical self. Melissa Hogenboom, BBC science journalist and author, explores the way societal expectations and cultural norms change the motherhood experience. She takes a journey with her family to her homeland, to understand why the Dutch are more relaxed when it comes to parenting.",0
60,"We introduce a novel, probabilistic binary latent variable model to detect noisy or approximate repeats of patterns in sparse binary data. The model is based on the ""Noisy-OR model"" (Heckerman, 1990), used previously for disease and topic modelling. The model's capability is demonstrated by extracting structure in recordings from retinal neurons, but it can be widely applied to discover and model latent structure in noisy binary data. In the context of spiking neural data, the task is to ""explain"" spikes of individual neurons in terms of groups of neurons, ""Cell Assemblies"" (CAs), that often fire together, due to mutual interactions or other causes. The model infers sparse activity in a set of binary latent variables, each describing the activity of a cell assembly. When the latent variable of a cell assembly is active, it reduces the probabilities of neurons belonging to this assembly to be inactive. The conditional probability kernels of the latent components are learned from the data in an expectation maximization scheme, involving inference of latent states and parameter adjustments to the model. We thoroughly validate the model on synthesized spike trains constructed to statistically resemble recorded retinal responses to white noise stimulus and natural movie stimulus in data. We also apply our model to spiking responses recorded in retinal ganglion cells (RGCs) during stimulation with a movie and discuss the found structure. ",1
61,"Sometimes, you go to the cinema to see a nuanced exploration of the human condition. But sometimes you go to see a blockbuster in which a Nasa official (Halle Berry) and a disgraced astronaut (Patrick Wilson) hijack a space shuttle after discovering that the Moon is actually a ""megastructure"" built by evil aliens. With a premise like that, it's hardly surprising that Moonfall is directed by Roland Emmerich, the maker of such sci-fi mass-destruction spectaculars as Independence Day, Godzilla, and The Day After Tomorrow. ""On the one hand, this is a disaster movie,"" he told Entertainment Weekly, ""but it's also a space movie; it's about space exploration and doing crazy things like flying inside the Moon. On the other hand, on Earth, their kids are getting into serious trouble. It's the best of both worlds.""",0
62,"The story begins with the Greeks who, sailing from Asia Minor, recognised the strategic deep-water port and settled in what is now Le Panier overlooking the Vieux Port. The Greeks traded with the Gauls, introducing grapes and olives to the region, unwittingly laying the foundation for Provençal cuisine.",0
63,"Using backpropagation to compute gradients of objective functions for optimization has remained a mainstay of machine learning. Backpropagation, or reverse-mode differentiation, is a special case within the general family of automatic differentiation algorithms that also includes the forward mode. We present a method to compute gradients based solely on the directional derivative that one can compute exactly and efficiently via the forward mode. We call this formulation the forward gradient, an unbiased estimate of the gradient that can be evaluated in a single forward run of the function, entirely eliminating the need for backpropagation in gradient descent. We demonstrate forward gradient descent in a range of problems, showing substantial savings in computation and enabling training up to twice as fast in some cases.",1
64,"The spirit of Exodus is multi-layered; its title track evokes the Old Testament tale of Moses leading his people to safety, and its parallels with Marley's Rastafarian faith. It also reflects Marley's own flight to London, amid the brutal turbulence of Jamaica's elections, and in the wake of a December 1976 assassination attempt that wounded him and his wife, vocalist Rita Marley. He would spend more than a year in the UK capital, during which Exodus (and its relatively breezy 1978 follow-up Kaya) were created.",0
65,"Horchata is indelibly linked to Valencia's success in tiger nut cultivation, a practice that began in Ancient Egypt (the tubers have even been found buried in pharaohs' tombs) before spreading throughout wider North Africa; from there it was introduced into Valencia following the Muslim conquest of Hispania in 711. Cultivation took hold in L'Horta Nord, part of a vast agricultural region on the city's outskirts, known in English as ""The Orchard"". It now takes place across 19 towns in the area, where the sandy soil coupled with Valencia's temperate climate makes for ideal growing conditions. About 5.3 million kilograms of tiger nuts are produced here, 90% of which are covered by a special Denomination of Origin status designed to regulate quality among regional products in the European Union.",0
66,"At the core of insurance business lies classification between risky and non-risky insureds, actuarial fairness meaning that risky insureds should contribute more and pay a higher premium than non-risky or less-risky ones. Actuaries, therefore, use econometric or machine learning techniques to classify, but the distinction between a fair actuarial classification and ""discrimination"" is subtle. For this reason, there is a growing interest about fairness and discrimination in the actuarial community Lindholm, Richman, Tsanakas, and Wuthrich (2022). Presumably, non-sensitive characteristics can serve as substitutes or proxies for protected attributes. For example, the color and model of a car, combined with the driver's occupation, may lead to an undesirable gender bias in the prediction of car insurance prices. Surprisingly, we will show that debiasing the predictor alone may be insufficient to maintain adequate accuracy (1). Indeed, the traditional pricing model is currently built in a two-stage structure that considers many potentially biased components such as car or geographic risks. We will show that this traditional structure has significant limitations in achieving fairness. For this reason, we have developed a novel pricing model approach. Recently some approaches have Blier-Wong, Cossette, Lamontagne, and Marceau (2021); Wuthrich and Merz (2021) shown the value of autoencoders in pricing. In this paper, we will show that (2) this can be generalized to multiple pricing factors (geographic, car type), (3) it perfectly adapted for a fairness context (since it allows to debias the set of pricing components): We extend this main idea to a general framework in which a single whole pricing model is trained by generating the geographic and car pricing components needed to predict the pure premium while mitigating the unwanted bias according to the desired metric.",1
67,"Local manmade early warning systems, such as tidal and earthquake sensors, failed to raise any clear alert. Many sensors were out of action due to maintenance issues, while many coastal areas lacked any tsunami siren warning systems. Haphazard communication also failed to provide warnings, with many text messages failing to reach mobiles in threatened areas or going unread.",0
68,"Bird Island is the most northern isle of the Seychelles' 115-island archipelago. It sits on the outer rim of the vast, undersea Mascarene Plateau, an extraordinary uplift of mid-ocean shallow water that covers an area larger than Portugal. The plateau begins at Bird Island and continues south for 2,000km, running almost the length of Madagascar. In the other direction, north of Bird, the Indian Ocean is deep, wide and uninterrupted by any landfall all the way to the Arabian Peninsula.",0
69,"In classical statistics, the bias-variance trade-off describes how varying a model's complexity (e.g., number of fit parameters) affects its ability to make accurate predictions. According to this trade-off, optimal performance is achieved when a model is expressive enough to capture trends in the data, yet not so complex that it overfits idiosyncratic features of the training data. Recently, it has become clear that this classic understanding of the bias-variance must be fundamentally revisited in light of the incredible predictive performance of ""overparameterized models"" -- models that avoid overfitting even when the number of fit parameters is large enough to perfectly fit the training data. Here, we present results for one of the simplest examples of an overparameterized model: regression with random linear features (i.e. a two-layer neural network with a linear activation function). Using the zero-temperature cavity method, we derive analytic expressions for the training error, test error, bias, and variance. We show that the linear random features model exhibits three phase transitions: two different transitions to an interpolation regime where the training error is zero, along with an additional transition between regimes with large bias and minimal bias. Using random matrix theory, we show how each transition arises due to small nonzero eigenvalues in the Hessian matrix. Finally, we compare and contrast the phase diagram of the random linear features model to the random nonlinear features model and ordinary regression, highlighting the new phase transitions that result from the use of linear basis functions. ",1
70,She captured the moments of everyday Stockport life while visiting a friend in town when she was a student at Stirling University. But she said the images were soon forgotten with the onset of motherhood and a full-time job in social work.,0
71,"When wildfires ravaged Abby Rose's farm in January 2017, every inch of her land was burned. Following many years of drought in Chile, temperatures exceeded 40C (104F) that summer and strong winds spread flames uncontrollably across southern and central regions for weeks. ",0
72,"Conditional variational autoencoders (CVAEs) are versatile deep generative models that extend the standard VAE framework by conditioning the generative model with auxiliary covariates. The original CVAE model assumes that the data samples are independent, whereas more recent conditional VAE models, such as the Gaussian process (GP) prior VAEs, can account for complex correlation structures across all data samples. While several methods have been proposed to learn standard VAEs from partially observed datasets, these methods fall short for conditional VAEs. In this work, we propose a method to learn conditional VAEs from datasets in which auxiliary covariates can contain missing values as well. The proposed method augments the conditional VAEs with a prior distribution for the missing covariates and estimates their posterior using amortised variational inference. At training time, our method marginalises the uncertainty associated with the missing covariates while simultaneously maximising the evidence lower bound. We develop computationally efficient methods to learn CVAEs and GP prior VAEs that are compatible with mini-batching. Our experiments on simulated datasets as well as on a clinical trial study show that the proposed method outperforms previous methods in learning conditional VAEs from non-temporal, temporal, and longitudinal datasets. ",1
73,"Known as the ""Crystal Eye"" to the Inuit, Pingualuit Crater was once the destination for diamond-seeking prospectors. But the real treasure is the stories its deep waters can tell. Back in 1950, this area was splashed across newspapers globally and pegged as the eighth wonder of the world. Not because of the wilderness, and not due to any manmade structure, but because of the distinct land feature I was now flying over en route taking another shot at the runway: Pingualuit Crater.",0
74,"We asked top UK chefs to tell us their favourite pub dishes, and the secrets to recreating those classic dishes at home. From baked potato mash using “an obscene amount of butter” to changing up your cheese in a ploughman's, these simple tricks (including some from Michelin-starred chefs) will bring the pub a little closer to home.",0
75,"Stochastic gradient descent (SGD) is widely used in deep learning due to its computational efficiency but a complete understanding of why SGD performs so well remains a major challenge. It has been observed empirically that most eigenvalues of the Hessian of the loss functions on the loss landscape of over-parametrized deep networks are close to zero, while only a small number of eigenvalues are large. Zero eigenvalues indicate zero diffusion along the corresponding directions. This indicates that the process of minima selection mainly happens in the relatively low-dimensional subspace corresponding to top eigenvalues of the Hessian. Although the parameter space is very high-dimensional, these findings seems to indicate that the SGD dynamics may mainly live on a low-dimensional manifold. In this paper we pursue a truly data driven approach to the problem of getting a potentially deeper understanding of the high-dimensional parameter surface, and in particular of the landscape traced out by SGD, by analyzing the data generated through SGD, or any other optimizer for that matter, in order to possibly discovery (local) low-dimensional representations of the optimization landscape. As our vehicle for the exploration we use diffusion maps introduced by R. Coifman and coauthors.",1
76,"In a submission to the International Court of Justice (ICJ), Germany says Italy continues to allow cases in its domestic courts despite a 2012 ruling that such claims were inadmissible. It says that, since that ruling, over 25 new cases have been filed in Italy In some of those, the courts have ruled that Germany should pay compensation.",0
77,Kylie Minogue and Jason Donovan will return to long-running Australian TV soap opera Neighbours for its finale after more than 30 years away.  They will resume their roles as much-loved characters Scott Robinson and Charlene Mitchell in the fictional Melbourne suburb of Erinsborough. ,0
78,"Convolutional neural network image classifiers are defined and the rate of convergence of the misclassification risk of the estimates towards the optimal misclassification risk is analyzed. Here we consider images as random variables with values in some functional space, where we only observe discrete samples as function values on some finite grid. Under suitable structural and smoothness assumptions on the functional a posteriori probability, which includes some kind of symmetry against rotation of subparts of the input image, it is shown that least squares plug-in classifiers based on convolutional neural networks are able to circumvent the curse of dimensionality in binary image classification if we neglect a resolution-dependent error term. The finite sample size behavior of the classifier is analyzed by applying it to simulated and real data.",1
79,"The eruption of the Tonga volcano in January has been confirmed as the biggest explosion ever recorded in the atmosphere by modern instrumentation.It was far bigger than any 20th Century volcanic event, or indeed any atom bomb test conducted after WWII.",0
